# 在Dify中使用AI威胁建模引擎

## 方式1：知识库集成（推荐）

### 1. 准备知识库

将以下文件导入Dify知识库：

**核心文档（必需）：**
- `SKILL.md` - 威胁建模引擎使用指南
- `威胁关联分析.md` - 威胁关联和攻击链分析
- `templates/threat-modeling-input.md` - 输入问卷
- `templates/threat-modeling-output.md` - 输出模板

**威胁知识库（26个威胁文档）：**
- `threats/` 目录下的所有 `.txt` 文件

### 2. 在Dify中创建知识库

1. 登录Dify工作空间
2. 进入"知识库"模块
3. 点击"创建知识库"
4. 命名：`AI威胁建模引擎`
5. 上传所有文档（支持批量上传）
6. 选择分段方式：
   - **推荐**：自动分段 + 自定义分隔符
   - 分段长度：800-1000 tokens
   - 重叠长度：150-200 tokens

### 3. 创建Agent应用

#### 应用配置

```yaml
应用名称: AI威胁建模专家
应用类型: Agent
模型: GPT-4 / Claude-3.5-Sonnet（推荐）
```

#### 系统提示词

```
你是一个专业的AI应用威胁建模专家，基于26个AI安全威胁知识库和STRIDE方法论。

你的工作流程：
1. 收集信息：询问用户应用类型、功能场景、架构信息等
2. 威胁识别：基于知识库筛选适用的威胁
3. 场景化分析：结合用户的具体场景描述威胁
4. 生成文档：输出完整的威胁模型文档

关键原则：
- 场景化：始终结合用户的具体功能场景
- 可操作：提供具体的修复建议，不要泛泛而谈
- 分级明确：P0/P1/P2分级，包含修复时限

当用户说"开始威胁建模"或"我要做威胁建模"时：
1. 先询问必需信息（Tier 1）：
   - 应用类型（对话助手/Agent/RAG/多模态/MCP）
   - 核心功能场景（2-3个详细场景）
   - 是否互联网开放
   - 数据类型（个人敏感/企业敏感/普通数据）
   - 技术栈（语言/框架/模型服务）

2. 根据需要询问重要信息（Tier 2）：
   - 整体架构
   - 认证方式
   - 权限模型
   - 是否有Agent工具
   - 日志记录情况

3. 基于输入筛选适用威胁（参考知识库中的条件触发规则）

4. 生成威胁模型文档（参考输出模板）

参考知识库中的SKILL.md了解详细工作流程。
```

#### 知识库配置

- 关联知识库：`AI威胁建模引擎`
- 检索模式：**混合检索**（语义 + 关键词）
- Top K：5-8
- Score阈值：0.5-0.6
- 重排序：开启

#### 工具配置（可选）

如果需要生成文档，可以添加：
- **代码执行器**：用于生成Markdown文档
- **HTTP请求**：如果需要对接其他系统

### 4. 使用流程

#### 场景1：新项目威胁建模

```
用户: "我要做威胁建模，我们要开发一个企业知识库问答助手"

AI: "好的！我是AI威胁建模专家，我会帮您识别安全威胁。

首先需要了解一些关键信息：

**应用类型确认：**
这是一个RAG知识库应用，对吗？

**核心功能场景：**
请描述2-3个典型使用场景，例如：
- 场景1：员工提问"公司的报销流程是什么？" → 系统检索知识库回答
- 场景2：...

**网络开放性：**
- [ ] 仅企业内网
- [ ] 内网+VPN远程访问  
- [ ] 互联网开放（需要登录）
- [ ] 互联网完全公开

**数据类型：**
知识库包含哪些类型的数据？
- [ ] 公开信息（官网、公告）
- [ ] 内部流程文档
- [ ] 商业机密
- [ ] 个人敏感信息

**技术栈：**
- 后端语言：Python/Node.js/Java/其他？
- 使用的模型：OpenAI/Azure/私有化部署/其他？
- 向量数据库：Pinecone/Milvus/其他？

请您提供这些信息。"

用户: [提供详细信息]

AI: [基于知识库分析，生成威胁模型文档]
"基于您提供的信息，我识别到12个适用威胁：

**威胁概览：**
- P0严重威胁：3个（需立即修复）
- P1高危威胁：7个（30天内修复）
- P2中危威胁：2个（90天内修复）

**最关键的3个风险：**

1. **提示词注入导致知识库越权访问** (P0)
   - 风险描述：用户可以通过提示词注入绕过权限限制...
   - 攻击场景：[具体场景]
   - 修复建议：[具体建议]
   - 修复时限：3天内

2. **训练数据知识库范围控制缺失** (P0)
   - [展开...]

3. **封装层服务未授权** (P0)
   - [展开...]

[继续输出完整威胁模型文档...]
"
```

#### 场景2：威胁查询

```
用户: "什么是提示词注入？"

AI: [检索知识库]
"提示词注入是AI应用最严重的威胁之一（P0级别）。

**漏洞原理：**
攻击者通过在用户输入中嵌入恶意指令，试图改变AI的行为，绕过系统提示词的限制...

[展开详细内容]

参考文档：threats/单模态：文字交互提示词注入.txt
"
```

---

## 方式2：作为Prompt模板

### 适用场景
如果您不需要完整的知识库，只想快速使用，可以直接将提示词嵌入到应用中。

### 配置步骤

1. **创建Agent应用**
2. **系统提示词**（简化版）：

```
你是AI威胁建模专家，基于STRIDE方法论识别AI应用安全威胁。

工作流程：
1. 收集信息：应用类型、功能场景、架构、数据类型
2. 威胁识别：从以下威胁库筛选适用威胁
3. 生成文档：包含威胁清单、风险矩阵、修复计划

威胁库（26个）：
- 提示词层(2): 系统提示词敏感信息(P1), 系统提示词恶意指令(P1)
- 模型越狱(4): 单模态提示词注入(P0), 多模态间接注入(P0), 混淆编码(P1), 角色扮演(P1), 渐进式攻击(P2)
- 模型DoS(2): 并发控制缺失(P2), 资源耗尽(P2)
- 训练安全(3): 数据范围控制缺失(P0), 数据投毒(P1), 训练数据获取(P2)
- MCP/权限(4): MCP权限校验缺陷(P0), 服务未授权(P0), API越权(P1), 功能级越权(P1)
- 代码执行(2): SQL注入(P0), 命令执行(P0)
- Web安全(2): XSS(P1), 前端信息泄露(P1)
- 文件操作(2): 任意文件操作(P1), 路径遍历(P1)
- 日志审计(2): 日志缺失(P2), 敏感日志打印(P1)
- 组件安全(1): 三方组件漏洞(P1)

必查威胁（所有应用）：
- 单模态提示词注入(P0)
- 系统提示词敏感信息(P1)
- 日志缺失(P2)

条件触发威胁：
- 互联网开放 → 并发控制缺失, 资源耗尽, 服务未授权
- 支持文件上传 → 多模态注入, 任意文件操作, 路径遍历
- 有Agent工具 → 操作边界控制, 命令执行
- 使用MCP → MCP权限校验
- 有数据库 → SQL注入
- 前端展示 → XSS, 前端泄露
- 企业敏感数据 → 数据范围控制, 数据投毒
- 有权限分级 → API越权, 功能级越权

场景化原则：
- 不说"可能有SQL注入"
- 要说"您的[具体功能]使用字符串拼接SQL，存在注入风险"

输出格式：
1. 威胁概览（P0/P1/P2分布）
2. 最关键的3个风险
3. STRIDE分类的详细威胁
4. 风险矩阵
5. 修复计划（P0:3-7天, P1:30天, P2:90天）
```

3. **不需要知识库**，但效果会差一些（没有详细的威胁文档内容）

---

## 方式3：工作流编排

### 适用场景
需要更复杂的交互流程和自动化处理。

### 配置步骤

1. **创建工作流应用**
2. **设计流程**：

```
开始
  ↓
[LLM节点1] 收集基本信息
  ↓
[条件分支] 判断应用类型
  ├─ RAG应用 → [LLM节点2] RAG专项威胁分析
  ├─ Agent应用 → [LLM节点3] Agent专项威胁分析
  └─ 多模态应用 → [LLM节点4] 多模态专项威胁分析
  ↓
[知识库检索] 检索适用的威胁文档
  ↓
[LLM节点5] 生成威胁模型文档
  ↓
[代码执行] 格式化为Markdown
  ↓
[HTTP请求] 发送到用户邮箱/存储系统（可选）
  ↓
结束
```

3. **每个LLM节点**都关联威胁建模知识库

---

## 推荐配置

### 最佳实践配置

```yaml
应用类型: Agent
模型选择: 
  - 首选: Claude-3.5-Sonnet（推理能力强）
  - 备选: GPT-4-Turbo
知识库: 必需
检索模式: 混合检索
Top K: 6-8
温度: 0.3（保持一致性）
最大Token: 4000+（生成完整文档）
```

### 提示词增强技巧

在系统提示词中加入：

```
输出要求：
1. 每个威胁必须包含具体场景，不能泛泛而谈
2. 必须标注来源（基于输入问卷的哪个部分）
3. 必须给出风险评级理由（影响 × 可能性）
4. 修复建议必须可操作（具体步骤 + 工作量 + 验证标准）
5. 必须生成优先级排序表

示例（好的输出）：
"威胁T-05：SQL注入
来源：输入问卷第八部分 - 数据库操作
根据问卷，您的[财务报表查询]功能使用字符串拼接SQL：
```python
query = f\"SELECT * FROM reports WHERE id = '{report_id}'\"
```
攻击者可输入 `1' OR '1'='1` 查看所有报表。
风险评级：P0（影响：高-数据泄露；可能性：高-无输入验证）
修复建议：使用参数化查询（预计2天，验证标准：所有SQL使用ORM）"

示例（不好的输出）：
"您的应用可能存在SQL注入风险，建议使用参数化查询。"
```

---

## 测试验证

配置完成后，测试以下场景：

1. **威胁建模流程**：
```
输入: "我要做威胁建模"
预期: AI主动询问必需信息，生成完整威胁模型文档
```

2. **威胁查询**：
```
输入: "什么是提示词注入？"
预期: 返回详细的漏洞原理、危害、修复方式
```

3. **场景化分析**：
```
输入: "我们的RAG应用使用了拼接SQL查询知识库"
预期: 识别SQL注入威胁，结合具体场景分析
```

---

## 常见问题

### Q1: 知识库检索不准确怎么办？

**解决方案：**
- 调整Top K到8-10
- 降低Score阈值到0.4-0.5
- 启用重排序
- 使用混合检索模式

### Q2: 生成的威胁模型不够场景化？

**解决方案：**
在系统提示词中强化：
```
关键要求：
- 每次输出前，回顾用户提供的具体场景
- 必须用"您的[具体功能]"开头
- 必须引用用户输入的具体信息
```

### Q3: 如何让AI主动询问信息？

**解决方案：**
在系统提示词中明确：
```
当信息不足时，必须主动询问：
- 缺少应用类型 → 询问是Agent/RAG/多模态/其他
- 缺少功能场景 → 询问核心业务流程
- 缺少架构信息 → 询问技术栈和部署方式
```

### Q4: 输出的文档太长，如何控制？

**解决方案：**
- 分阶段输出：先概览，用户确认后再详细展开
- 添加提示词：
```
输出策略：
1. 先输出威胁概览和最关键的3个风险
2. 询问用户："是否需要完整的威胁模型文档？"
3. 如果需要，再输出完整的10个部分
```

---

## 进阶用法

### 集成到CI/CD

如果使用Dify API：

```python
import requests

def threat_modeling(app_info):
    """调用Dify威胁建模Agent"""
    url = "https://api.dify.ai/v1/chat-messages"
    headers = {
        "Authorization": "Bearer YOUR_API_KEY",
        "Content-Type": "application/json"
    }
    data = {
        "inputs": {},
        "query": f"请对以下应用进行威胁建模：\n{app_info}",
        "user": "devops-pipeline"
    }
    response = requests.post(url, headers=headers, json=data)
    return response.json()

# 在CI/CD中使用
app_info = """
应用类型：RAG知识库
功能场景：员工查询企业文档
网络开放：互联网开放（需登录）
数据类型：企业敏感信息
技术栈：Python/FastAPI/OpenAI
"""

result = threat_modeling(app_info)
print(result['answer'])
```

---

## 总结

**推荐方案：** 方式1（知识库集成）

**优点：**
- 完整的威胁知识库支持
- 场景化分析能力强
- 可以查询具体威胁详情
- 输出质量高

**快速上手：**
1. 上传所有文档到Dify知识库（5分钟）
2. 创建Agent应用（3分钟）
3. 复制系统提示词（1分钟）
4. 开始使用（立即）

总计：10分钟即可在Dify中部署威胁建模引擎！
